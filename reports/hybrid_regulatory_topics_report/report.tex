\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{float}

\hypersetup{hidelinks}

% Generated by scripts/build_hybrid_regulatory_topics_latex_report.py
\IfFileExists{provenance.tex}{\input{provenance.tex}}{}

\title{Hybrid Regulatory Topic Discovery: From Chunk Topics to Clause-Level Instruments}
\author{}
\date{\IfFileExists{provenance.tex}{\ReportDate}{(run builder to populate provenance)}}

\begin{document}
\maketitle

\section{Problem and goal}

PI feedback motivating this work:
\begin{quote}
\emph{The pure clustering approach is interesting but isnâ€™t surfacing regulatory topics or questions to a sufficiently granular degree.}
\end{quote}

The key design change is to shift the clustering target from \textbf{whole chunks} (which can mix multiple themes)
to \textbf{atomic clauses/requirements} (which are closer to ``regulatory instruments'').

\section{Baseline: chunk-level topic clustering (existing pipeline)}

The repository already contains a mature chunk-topic discovery pipeline
(provider embeddings $\rightarrow$ UMAP $\rightarrow$ HDBSCAN $\rightarrow$ LLM labels).

\IfFileExists{figures/baseline_full_ordinance_umap.png}{
\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/baseline_full_ordinance_umap.png}
  \caption{Baseline example: chunk-level UMAP + HDBSCAN scatter (full ordinances). Each point is a chunk, so mixed-content chunks limit topic specificity.}
\end{figure}
}{}

\IfFileExists{tables/baseline_top_clusters.tex}{\input{tables/baseline_top_clusters.tex}}{}

\section{Hybrid pipeline (implemented)}

The implemented hybrid workflow is documented in:
\begin{itemize}[leftmargin=*]
  \item \texttt{docs/hybrid\_regulatory\_topics\_workflow.md}
\end{itemize}

At a high level:
\begin{enumerate}[leftmargin=*]
  \item Segment each document into coherent sections (optional but PI-recommended).
  \item Label each section with a \emph{primary regulatory motive} (controlled taxonomy).
  \item Extract \emph{atomic clauses/requirements} per section (LLM; strict schema when run via OpenAI Batch).
  \item Embed + cluster extracted clauses to discover granular instruments.
  \item Label clause clusters into human-readable instruments (LLM).
\end{enumerate}

\subsection{Concrete artifacts (scripts and prompts)}

The pipeline above corresponds to concrete repo artifacts:
\begin{itemize}[leftmargin=*]
  \item Section segmentation:
    \texttt{scripts/export\_regulatory\_section\_segmentation\_batch\_requests.py},
    \texttt{scripts/rehydrate\_regulatory\_section\_segmentation\_openai\_batch\_results.py},
    prompt \texttt{prompts/regulatory\_section\_segmenter\_prompt\_text.txt}.
  \item Motive labeling:
    \texttt{scripts/export\_regulatory\_motive\_batch\_requests.py},
    \texttt{scripts/rehydrate\_regulatory\_motive\_openai\_batch\_results.py},
    prompt \texttt{prompts/regulatory\_motive\_classifier\_prompt\_text.txt}.
  \item Clause extraction:
    \texttt{scripts/export\_regulatory\_clause\_extraction\_batch\_requests.py},
    \texttt{scripts/rehydrate\_regulatory\_clause\_extraction\_openai\_batch\_results.py},
    prompt \texttt{prompts/regulatory\_clause\_extractor\_prompt\_text.txt}.
  \item Clause clustering:
    local \texttt{scripts/cluster\_regulatory\_clauses\_local.py} (TF--IDF $\rightarrow$ SVD $\rightarrow$ UMAP $\rightarrow$ HDBSCAN),
    or embedding-based \texttt{scripts/export\_clause\_embedding\_batch\_requests.py} +
    \texttt{scripts/rehydrate\_clause\_embeddings\_openai\_batch\_results.py} +
    \texttt{scripts/cluster\_clause\_embeddings.py}.
  \item Cluster $\rightarrow$ instrument labeling:
    \texttt{scripts/export\_regulatory\_instrument\_cluster\_labeling\_batch\_requests.py},
    \texttt{scripts/rehydrate\_regulatory\_instrument\_cluster\_labels\_openai\_batch\_results.py},
    prompt \texttt{prompts/regulatory\_instrument\_cluster\_labeler\_prompt\_text.txt}.
  \item Human inspection packet:
    \texttt{scripts/build\_regulatory\_instrument\_cluster\_report.py}.
  \item RHS-style panels from instrument clusters:
    \texttt{scripts/build\_regression\_rhs\_from\_instrument\_clusters.py}.
\end{itemize}

\section{Smoke test: real ordinance sample}

This report is grounded in a concrete run directory:
\begin{itemize}[leftmargin=*]
  \item Hybrid run: \HybridRunDir
\end{itemize}

\subsection{Section segmentation}

\IfFileExists{tables/sections_index.tex}{\input{tables/sections_index.tex}}{}

\subsection{Motive labeling summary}

\IfFileExists{tables/chunk_motive_counts.tex}{\input{tables/chunk_motive_counts.tex}}{}

\subsection{Clause extraction summary}

\IfFileExists{tables/clause_motive_counts.tex}{\input{tables/clause_motive_counts.tex}}{}
\IfFileExists{tables/clause_modality_counts.tex}{\input{tables/clause_modality_counts.tex}}{}

\subsection{Clause clustering (instrument discovery)}

\IfFileExists{figures/hybrid_clause_umap.png}{
\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/hybrid_clause_umap.png}
  \caption{Hybrid example: clause-level UMAP + HDBSCAN scatter. Each point is a single extracted requirement, which enables instrument-level clusters.}
\end{figure}
}{}

\IfFileExists{tables/cluster_index.tex}{\input{tables/cluster_index.tex}}{}

\subsection{Example instrument clusters (verbatim evidence)}

\IfFileExists{snippets/cluster_examples.tex}{\input{snippets/cluster_examples.tex}}{}

\subsection{Document-level purposes (LLM)}

\IfFileExists{tables/doc_purposes.tex}{\input{tables/doc_purposes.tex}}{}

\section{Why this improves granularity}

Chunk clustering often groups together:
\begin{itemize}[leftmargin=*]
  \item multiple regulatory instruments inside one ordinance section, and/or
  \item ordinance text mixed with publication notices, hearings, meeting minutes, ads, etc.
\end{itemize}

The hybrid pipeline clusters \textbf{atomic requirements}, which makes it easier to surface:
\begin{itemize}[leftmargin=*]
  \item distinct instruments inside the same ordinance (e.g., parking minimums by use vs.\ loading standards),
  \item stable, interpretable ``RHS-style'' covariates built from instrument clusters.
\end{itemize}

\section{Known limitations and next knobs}

\begin{itemize}[leftmargin=*]
  \item Some clusters are administrative/procedural (e.g., governance rules). Decide whether to keep or filter them.
  \item Local gateway runs may not enforce OpenAI-side JSON-schema output; prefer Batch for large runs.
  \item For regression use, cluster IDs are run-specific; treat a clustering run as a frozen artifact or build a stable mapping layer.
\end{itemize}

\end{document}
